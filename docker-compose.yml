version: "3.3"

services:
  
  zookeeper:
    image: confluentinc/cp-zookeeper:latest
    container_name: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    networks:
      - my-network
    ports:
      - "22181:2181"
  
  kafka:
    build: ./kafka
    image: kafka:compose
    container_name: kafka
    networks:
      - my-network
    depends_on:
      - zookeeper
    ports:
      - "29092:29092"
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'
    healthcheck:
      test: ["CMD-SHELL", "nc -z kafka 9092 || exit 1"]
      interval: 5s
      timeout: 10s
      retries: 5

  cassandra:
      image: cassandra:latest
      container_name: cassandra
      networks:
      - my-network
      ports:
        - "9042:9042"
      environment:
        - "MAX_HEAP_SIZE=256M"
        - "HEAP_NEWSIZE=128M"
      restart: always
      volumes:
        - ./cassandra_db/data:/var/lib/cassandra

  cassandra-load-keyspace:
      container_name: cassandra-load-keyspace
      image: cassandra:latest
      networks:
      - my-network
      depends_on:
        - cassandra
      volumes:
        - ./cassandra_db/schema.cql:/schema.cql 
      command: /bin/bash -c "sleep 60 && echo loading cassandra keyspace && cqlsh cassandra -f /schema.cql"

  # visualization:
  #   build: ./visualization
  #   image: visualization:compose
  #   container_name: visualization
  #   depends_on:
  #     kafka:
  #       condition: service_healthy  # Attendere che Kafka sia segnalato come "healthy"
  #   networks:
  #     - my-network
  #   ports:
  #     - "8501:8501"
  #   environment:
  #     KAFKA_BOOTSTRAP_SERVERS: kafka:9092
  #   volumes:
  #     - ./datasets/test:/input

<<<<<<< HEAD
  batch-spark:
    build: ./batch_preprocessing_analysis
    image: batch-spark:compose
    container_name: batch-spark
    depends_on:
      kafka:
        condition: service_healthy  # Attendere che Kafka sia segnalato come "healthy"
    networks:
      - my-network
    ports:
      - "4040:4040"
      - "7077:7077"
    environment:
      KAFKA_BOOTSTRAP_SERVERS: kafka:9092
    volumes:
      - ./datasets:/input
    # command: bash -c "while ! nc -z 127.0.0.1 9092; do sleep 1; done && python ./producer.py"
=======

  # batch-spark:
  #   build: ./batch_preprocessing_analysis
  #   image: batch-spark:compose
  #   container_name: batch-spark
  #   depends_on:
  #     kafka:
  #       condition: service_healthy  # Attendere che Kafka sia segnalato come "healthy"
  #   networks:
  #     - my-network
  #   ports:
  #     - "4040:4040"
  #     - "7077:7077"
  #   environment:
  #     KAFKA_BOOTSTRAP_SERVERS: kafka:9092
  #   volumes:
  #     - ./datasets:/input
  #   # command: bash -c "while ! nc -z 127.0.0.1 9092; do sleep 1; done && python ./producer.py"
>>>>>>> 3a992f52a9b12b23669cb7f2a81d127bec10bcfd

  influxdb:
    image: influxdb
    container_name: influxdb
    networks:
      - my-network
    ports:
      - "8086:8086"  # Esponi la porta 8086 di InfluxDB
    environment:
     - INFLUXDB_USER=user
     - INFLUXDB_PASS=password
     - INFLUXDB_DB=iothome

  grafana:
    image: grafana/grafana:main
    container_name: grafana
    networks:
      - my-network
    ports:
      - "3000:3000"  # Esponi la porta 3000 di Grafana
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=architetture_lambda  # Imposta la password dell'amministratore di Grafana
      # - GF_USERS_ALLOW_SIGN_UP=false  # Disabilita la registrazione di nuovi utenti in Grafana
    # volumes:
    #   - ./grafana-data:/var/lib/grafana  # Percorso per la persistenza dei dati di Grafana

  producer:
    build: ./producer
    image: producer:compose
    container_name: producer
    depends_on:
      kafka:
        condition: service_healthy  # Attendere che Kafka sia segnalato come "healthy"
    networks:
      - my-network
    environment:
      KAFKA_BOOTSTRAP_SERVERS: kafka:9092
    volumes:
      - ./datasets:/input
    # command: bash -c "while ! nc -z 127.0.0.1 9092; do sleep 1; done && python ./producer.py"

  streaming-spark:
    build: ./streaming
    image: streaming-spark:compose
    container_name: streaming-spark
    depends_on:
      kafka:
        condition: service_healthy  # Attendere che Kafka sia segnalato come "healthy"
      # influxdb:
      #   condition: service_healthy  # Attendere che InfluxDB sia segnalato come "healthy"
    networks:
      - my-network
    ports:
      - "4041:4040"
      - "7078:7077"
    environment:
      - SPARK_APPLICATION_MAIN_CLASS=your.main.Class
      - SPARK_APPLICATION_ARGS=--bootstrap.servers=kafka:9092 --topic=my-topic

networks:
  my-network: