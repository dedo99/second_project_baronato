version: "3.3"


services:
  batch-spark:
    build: ./batch_preprocessing_analysis
    image: batch-spark:compose
    networks:
      - my-network
    ports:
      - "4040:4040"
      - "7077:7077"
    environment:
      - SPARK_MODE=master
      - SPARK_MASTER_URL=spark://spark-master:7077
    volumes:
      - ./HomeC.csv:/input/HomeC.csv

  zookeeper:
    image: confluentinc/cp-zookeeper:latest
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - 22181:2181
  
  kafka:
    build: ./kafka
    image: kafka:compose
    depends_on:
      - zookeeper
    ports:
      - 29092:29092
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    volumes:
      - ./kafka/scripts:/home/appuser/scripts

  # cassandra:
  #   image: cassandra:latest
  #   container_name: cassandra
  #   networks:
  #     - my-network
  #   ports:
  #     - "9042:9042"
  #   environment:
  #     - "MAX_HEAP_SIZE=256M"
  #     - "HEAP_NEWSIZE=128M"
  #   volumes:
  #     - ./cassandra_db/data:/var/lib/cassandra
      # - ./cassandra_db/script:/docker-entrypoint-initdb.d
    # command: bash -c 'sleep 10 && cqlsh -f /init-script.cql cassandra'


networks:
  my-network:
    driver: bridge